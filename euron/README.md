# school-notification-classfication-task

# í•™êµ ê³µì§€ì‚¬í•­ ë¶„ë¥˜ í”„ë¡œì íŠ¸

## Experiment Results

*acc ê¸°ì¤€

|  | Multilingual BERT | KoBERT | KoBERT with LLRD |
| --- | --- | --- | --- |
| Test | 0.90530 | 0.8976 | 0.8982 |

## #01 í”„ë¡œì íŠ¸ ì†Œê°œ

ğŸ’¡ í”„ë¡œì íŠ¸ì˜ í•„ìš”ì„± ë° ê°œìš”

í•™êµ ê³µì§€ì‚¬í•­ì—ì„œ í•™ì‚¬, ê²½ë ¥, ì¥í•™ ë“± ì¹´í…Œê³ ë¦¬ì˜ ê²½ê³„ê°€ ëª¨í˜¸í•˜ì—¬ ì‚¬ìš©ì ì…ì¥ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì–»ì§€ ëª»í•˜ëŠ” ì ì—ì„œ ë¶ˆí¸ì„ ëŠë‚Œ.

íŠ¹íˆ, í™ˆí˜ì´ì§€ì˜ ì£¼ ì‚¬ìš©ì¸µì¸ í•™ìƒì˜ ì£¼ìš” ê´€ì‹¬ì‚¬ëŠ” **ìŠ¤í™ì„ ìŒ“ì„ ìˆ˜ ìˆëŠ” í™œë™ì— ëŒ€í•œ ê³µì§€ì‚¬í•­**ì„.

â¡ï¸ ê³µì§€ì‚¬í•­ì„ ìŠ¤í™ì´ ë˜ëŠ” ê²ƒ(1)ê³¼ ê·¸ë ‡ì§€ ì•Šì€ ê²ƒ(0)ìœ¼ë¡œ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³ ì í•¨.

## #02 ë°ì´í„° í¬ë¡¤ë§

- title scrapping í•¨ìˆ˜ë¥¼ ì •ì˜ â†’ BeautifulSoup ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ì›í•˜ëŠ” í˜ì´ì§€ì˜ ì›í•˜ëŠ” ë¶€ë¶„ì„ í¬ë¡¤ë§í•  ìˆ˜ ìˆìŒ.
- í™ˆí˜ì´ì§€ì˜ ê°œë°œì ëª¨ë“œë¥¼ í†µí•´ ìŠ¤í¬ë˜í•‘í•˜ê³ ì í•˜ëŠ” ë¶€ë¶„ì´ ì–´ë–¤ íƒœê·¸, ì–´ë–¤ í´ë˜ìŠ¤ì¸ì§€ í™•ì¸ í›„ ì›í•˜ëŠ” ë¶€ë¶„ì„ find ë˜ëŠ” find_all ë©”ì„œë“œë¥¼ í†µí•´ í¬ë¡¤ë§í•  ìˆ˜ ìˆìŒ.
- í¬ë¡¤ë§í•œ 9782ê°œì˜ train setê³¼ 976ê°œì˜ test setì„ ëª¨ë‘ ì§ì ‘ ë¼ë²¨ë§í•¨.

## #03 EDA

- í•œê¸€ í°íŠ¸ (ë‚˜ëˆ” í°íŠ¸ ì„¤ì¹˜) - ì„¤ì¹˜ í›„ ì„¸ì…˜ ë‹¤ì‹œ ì‹œì‘
- ê²°ì¸¡ì¹˜ í™•ì¸ & ì¤‘ë³µ ì œê±°
- class balance í™•ì¸: train dataì˜ class imbalanceëŠ” smote / oversampling / undersamplingê³¼ ê°™ì€ ë°ì´í„° ì¡°ì‘ì„ í•„ìš”ë¡œ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í™•ì¸í•´ì•¼ í•  ì¤‘ìš”í•œ ìš”ì†Œ
- title length íŒŒì•…: í´ë˜ìŠ¤ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ê°€ í¬ê²Œ ë‹¤ë¥´ì§€ ì•ŠìŒì„ í™•ì¸í•¨
- word cloudë¡œ í´ë˜ìŠ¤ ë³„ ì–´ë–¤ ë‹¨ì–´ê°€ dominantí•œ ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸

## #04 ì „ì²˜ë¦¬

- ì¶œí˜„ ë¹ˆë„ê°€ ë‚®ì€ ë‹¨ì–´ ì œê±°: Counter()ë¥¼ ì‚¬ìš©í•´ ëª¨ë“  ë‹¨ì–´ì˜ ì¶œí˜„ ë¹ˆë„ ìˆ˜ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥, ì´í›„ ë¹ˆë„ ìˆ˜ê°€ 3ë²ˆ ì´í•˜ì¸ ë‹¨ì–´ë¥¼ ì œê±°
- í¬ë¡¤ë§í•œ í•™êµ ëª…ì„ 95% ì œê±° â†’ íŠ¹ì • í•™êµëª…ìœ¼ë¡œ í•™ìŠµë˜ëŠ” ì¼ì„ ë°©ì§€
- titleì— ì˜ì–´ì™€ í•œêµ­ì–´ë§Œ ë‚¨ê¸°ê³  ìˆ«ì, ê´„í˜¸, íŠ¹ìˆ˜ ë¬¸ìëŠ” ëª¨ë‘ ì œê±°
- custom wordsì™€ stop words ì •ì˜: â€˜ì¥í•™ìƒâ€™ê³¼ ê°™ì€ í•˜ë‚˜ì˜ ë‹¨ì–´ì´ì ë¶„ë¥˜ í…ŒìŠ¤í¬ì—ì„œì˜ ì£¼ìš” í‚¤ì›Œë“œë¥¼ â€˜ì¥â€™, â€˜í•™ìƒâ€™ìœ¼ë¡œ ì˜ëª» ì¸ì‹í•˜ì—¬ í† í°í™”í•˜ëŠ” ê²½ìš° ë°œìƒ â†’ custom wordsë¥¼ ì •ì˜í•´ ì‚¬ìš©ì ì§€ì • ì‚¬ì „ ì œì‘
- í•œ ê¸€ìëŠ” dropí•˜ë˜ â€˜íŒ€â€™, â€˜ë©â€™ê³¼ ê°™ì€ ì£¼ìš” í‚¤ì›Œë“œëŠ” ë‚¨ê²¨ë‘ê¸°

## #05 ëª¨ë¸ë§

### Embedding

---

- n-gram vectorization: ë‹¨ì–´ì˜ ì•ë’¤ ë§¥ë½ ì •ë³´ë¥¼ ë” ì˜ íŒŒì•…í•˜ê¸° ìœ„í•œ ì‘ì—…
- Kobert Tokenizer: í•œêµ­ì–´ì˜ í˜•íƒœì†Œ ë¶„ì„ì„ ë°˜ì˜í•˜ì—¬ ë” ì˜ë¯¸ ìˆëŠ” ì„ë² ë”©ì„ í˜•ì„±í•  ìˆ˜ ìˆìŒ.
- high priority words: â€˜í”„ë¡œê·¸ë¨â€™, â€˜ì„œí¬í„°ì¦ˆâ€™, â€˜ì¸í„´â€™ê³¼ ê°™ì´ ë¶„ë¥˜ì— ìˆì–´ ì¤‘ìš”ë„ê°€ ë†’ì€ ë‹¨ì–´ë“¤ì„ í¬í•¨í•˜ëŠ” titleì„ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ìœ¼ë¡œ ì„¤ì •í•œ ë’¤ machine learning modelì„ ì‹¤í–‰í•  ë•Œ ê·¸ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì„.

â‡’ ìµœì¢…ì ìœ¼ë¡œ ì„ë² ë”© ë° ì¤‘ìš”ë„ë¥¼ ë†’ì¸ ë‹¨ì–´ë“¤ì˜ íŠ¹ì§•ì„ X_combined ë³€ìˆ˜ì— stacking

### Machine Learning Model

---

*acc ê¸°ì¤€ 

|  | Random Forest | Multinomial Naive Bayes | Bernoulli Naive Bayes | Logistic Regression (ver. plain)  | Logistic Regression (ver. optimal hyperparameters with GridSearch) |
| --- | --- | --- | --- | --- | --- |
| ì¼ë°˜ ë²„ì „ | 0.8456 | 0.8844 | 0.8942 | 0.7052 | 0.9131 |
| íŠ¹ì • ë‹¨ì–´ ì¤‘ìš”ë„ ë†’ì¸ ë²„ì „  | 0.8456 | 0.8850 | 0.8942 | 0.7041 | 0.9131 |

### Deep Learning Model

---

### Multilingual BERT

- ë‹¤ì–‘í•œ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ BERT â†’ ì¼ë°˜í™”ëœ ì–¸ì–´ í‘œí˜„ì„ í•™ìŠµ
- trained with self-supervised fashion (no ground-truth label)
- Pretrained objectives
    - Masked Language Modeling(MLM): randomly masks 15% of the input words â†’ learn bidirectional represenation of word
    - Next Sentence Prediction(NSP): concatenates two masked sentences â†’ predict whether two sentences are successive or not
- In this way, M-BERT learns an inner represenation of languages that can be useful in extracting features for each downstream task

### **Process**

1. titleì˜ ì‹œì‘ì— [CLS], ëì— [SEP] í† í°ì„ ë¶™ì„. [CLS]ëŠ” classificationì˜ ì•½ìë¡œ, ë¬¸ì¥ì˜ ì‹œì‘ì— ë¶™ì„ìœ¼ë¡œì¨ ì´ ìœ„ì¹˜ì—ì„œ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ë„ë¡ ëª¨ë¸ì—ê²Œ ì•Œë¦¼. [SEP]ëŠ” separatorì˜ ì•½ìë¡œ, ë¬¸ì¥ì˜ ëì— ë¶™ì„ìœ¼ë¡œì¨ ì„œë¡œ ë‹¤ë¥¸ ë¬¸ì¥ë“¤ì„ êµ¬ë¶„í•¨. 
2. ë¬¸ì¥ì˜ ë‹¨ì–´ë¥¼ tokenzing: tokenizer
    
    ```python
    tokenizer = BertTokenizer.from_pretrained('bert-base-multillingual-cased', do_lower_case = False)
    tokenized_X_train = [tokenizer.tokenize(fixed) for fixed in X_train_fixed]
    tokenized_X_test = [tokenizer.tokenize(fixed) for fixed in X_test_fixed]
    ```
    
3. tokenì„ ê°ê° ëŒ€ì‘í•˜ëŠ” idë¡œ ë‚˜íƒ€ëƒ„
4. pad sequenceë¥¼ í†µí•´ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì§€ì •í•œ ê¸¸ì´ì¸ max_lenìœ¼ë¡œ ë§ì¶°ì¤Œ. ë¹ˆ ë¶€ë¶„ì€ 0ìœ¼ë¡œ íŒ¨ë”©. 
5. ë¬¸ì¥ì˜ attention maskë¥¼ ë§Œë“¦ - idê°€ ì¡´ì¬í•˜ë©´ 1.0, 0ìœ¼ë¡œ íŒ¨ë”©ëìœ¼ë©´ 0.0ìœ¼ë¡œ maskë¥¼ ë§Œë“¦
6. hyperparameter setting: ë°°ì¹˜ ì‚¬ì´ì¦ˆ, ì—í­ ìˆ˜, learning rate scheduler ì¡°ì ˆì„ í†µí•´ ìµœì ì˜ accuracyë¥¼ ê°€ì§€ëŠ” hyperparameterë¥¼ ì°¾ìŒ

| lr scheduler ì‚¬ìš© ì—¬ë¶€ | batch size | epochs | step size | gamma  | learning scheduler | learning rate | optimzier |
| --- | --- | --- | --- | --- | --- | --- | --- |
| o | 32 | 10 | 3 | 0.1 | StepLR | 3e-5 | AdamW |
1. 10ë²ˆì˜ ì—í­ ë™ì•ˆ overfittingì„ ë§‰ê¸° ìœ„í•´ early stopping ê¸°ë²• ì ìš©: eval lossê°€ ì„¸ ë²ˆ ë™ì•ˆì´ë‚˜ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ overfittingì´ë¼ê³  íŒë‹¨í•˜ê³  í›ˆë ¨ ì¢…ë£Œ â†’ 7ë²ˆì˜ epochì—ì„œ í›ˆë ¨ì´ ì¢…ë£Œë¨

### KoBERT

- ê¸°ì¡´ BERTì˜ í•œêµ­ì–´ ì„±ëŠ¥ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ SKT Brainì—ì„œ ê°œë°œí•œ ëª¨ë¸
- ìœ„í‚¤í”¼ë””ì•„ì™€ ë‰´ìŠ¤ ë“±ì—ì„œ ìˆ˜ì§‘í•œ ìˆ˜ë°±ë§Œ ê°œì˜ í•œêµ­ì–´ ë¬¸ì¥ì˜ ëŒ€ê·œëª¨ ë§ë­‰ì¹˜(Corpus)ë¥¼ í†µí•´ í•™ìŠµë¨
- output layerë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ì–¸ì–´ íŠ¹í™” ëª¨ë¸ì„ customizeí•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì  ì¡´ì¬

### **Process**

1. Bert Classifier Architecture ì •ì˜: 
2. get_cosine_schedule_with_warmupì„ í™œìš©í•œ learning rate scheduling: í•™ìŠµ ì´ˆê¸° ë‹¨ê³„ì—ì„œ í•™ìŠµìœ¨ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ëŠ” warming-up stepì„ ì ìš©í•œ í›„, cosine í˜•íƒœë¡œ í•™ìŠµìœ¨ì„ ì ì°¨ ê°ì†Œì‹œí‚¤ëŠ” ë°©ì‹ 
3. Layer-wise Learning Rate Decay(LLRD) ì ìš©: ëª¨ë¸ì˜ ê° ë ˆì´ì–´ë§ˆë‹¤ ë‹¤ë¥¸ í•™ìŠµìœ¨ì„ ì ìš©ì‹œí‚¤ëŠ” ê¸°ë²•ìœ¼ë¡œ, ìƒìœ„ ë ˆì´ì–´ëŠ” ë³´ë‹¤ êµ¬ì²´ì ì¸ ì˜ë¯¸ / í…ŒìŠ¤í¬ íŠ¹í™” ì •ë³´ë¥¼ ë‹´ê³  ìˆê³  í•˜ìœ„ ë ˆì´ì–´ëŠ” ê¸°ë³¸ì ì€ ë¬¸ë²•, ì–´íœ˜, êµ¬ì¡°ì  ì •ë³´ ë“±ì„ ë‹´ê³  ìˆìŒ. ë”°ë¼ì„œ í•˜ìœ„ ë ˆì´ì–´ì—ì„œëŠ” ì‘ì€ learning rateë¡œ ì¼ë°˜ì ì´ê³  ê¸°ë³¸ì ì¸ êµ¬ì¡°ë¥¼ í•™ìŠµí•œ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìƒìœ„ ë ˆì´ì–´ì—ì„œëŠ” ë†’ì€ learning rateë¡œ í…ŒìŠ¤í¬ì— íŠ¹í™”ë˜ë„ë¡ íŒŒë¼ë¯¸í„°ê°€ ì‹ ì†í•˜ê²Œ ì—…ë°ì´íŠ¸ë˜ì–´ì•¼ í•¨. â†’ í•˜ìœ„ 6ê°œ layerëŠ” learning rateë¡œ 0.1, ìƒìœ„ 6ê°œ layerëŠ” learning rateë¡œ 0.5ë¥¼ ê°€ì§
4. LLRDë¥¼ ì ìš©í•œ ëª¨ë¸ì´ ê·¸ë ‡ì§€ ì•Šì€ ëª¨ë¸ë³´ë‹¤ outperformed

## Hyperparameters Tuning

# íŒŒì¸íŠœë‹ ê¸°ë¡ - multilingual bert

## ì‚¬ìš© ëª¨ë¸

---

[google-bert/bert-base-multilingual-cased Â· Hugging Face](https://huggingface.co/google-bert/bert-base-multilingual-cased)

## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

---

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 2e-5 | 3 | 0.1 | 10 | 0.90020 | 32 |

![image](https://github.com/user-attachments/assets/580654b7-0d71-4b9f-9223-7c1b828187f7)

![image 1](https://github.com/user-attachments/assets/fff31a3c-4d10-4db1-b0cd-8fd1eecea6ad)

BERT ê³µì‹ ë¬¸ì„œì—ì„œ ì‹œë„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì°¸ê³  - 4 epoch

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 1e-4 | 3 | 0.1 | 4 | 0.87478 | 32 |

![image 2](https://github.com/user-attachments/assets/9266cf69-ec2a-4b40-8f54-652cf72a26e1)

ì´ˆê¸° learning rateê°€ ë„ˆë¬´ ì»¸ë˜ ê²ƒìœ¼ë¡œ ì˜ˆìƒ. ë˜í•œ ì—í­ì´ 4ì¸ë° step sizeê°€ 3ì´ë¯€ë¡œ lr schedulingì´ ê±°ì˜ íš¨ê³¼ê°€ ì—†ì—ˆë˜ ë“¯. 

### ğŸŒŸ

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 3e-5 | 3 | 0.1 | 10 | **0.90974** | 32 |

![image 3](https://github.com/user-attachments/assets/374e472b-cb6a-4afb-8fa7-1c1c09234899)

![image 4](https://github.com/user-attachments/assets/00cd7c05-1633-4064-a0c6-ec7d1673be37)

![image 5](https://github.com/user-attachments/assets/f0a68d80-57b3-4060-b69e-6240b37d8bb0)
ğŸŒŸÂ m-bert.pth: **0.90503**

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 3e-5 | 3 | 0.1 | 4 | 0.90238 | 32 |

![image 6](https://github.com/user-attachments/assets/6d5fba5c-dfde-466b-af4a-ec3ca17fd7c8)


|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 3e-5 | 1 | 0.1 | 4 | 0.89697 | 32 |

![image 7](https://github.com/user-attachments/assets/dfbc1efa-16ba-4580-91f4-6c6a0930f795)


|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 3e-5 | 3 | 0.1 | 10 | 0.89912 | 16 |

![image 8](https://github.com/user-attachments/assets/f7544813-b6dd-4679-9d30-9f808607f5e7)

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 3e-5 | 3 | 0.1 | 10 | 0.89540 | 64 |

![image 9](https://github.com/user-attachments/assets/2b1f5dc2-96fb-40eb-b0d5-d48b52b59e87)

ë°°ì¹˜ ì‚¬ì´ì¦ˆëŠ” 32ê°€ ì ë‹¹í•œ ê±¸ë¡œ

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | base_lr(ì´ˆê¸° lr) | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size | max_lr | mode |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | CyclicLR | 3e-8 | 3 | 0.5 | 10 | 0.89703 | 32 | 3e-5 | exp_range |

![image 10](https://github.com/user-attachments/assets/4d30bd29-3305-48b9-99c4-d831aaf7496a)

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 5e-5 | 3 | 0.1 | 10 | 0.90132 | 32 |

![image 11](https://github.com/user-attachments/assets/93b84f6f-d3f3-4663-bca0-4632b415469e)


### ğŸŒŸÂ Early Stopping ì ìš©í•´ì„œ ê³¼ì í•© ë§‰ì•„ë³´ê¸°

|  | ì‚¬ìš© ì—¬ë¶€ | ì¢…ë¥˜ | ì´ˆê¸° LR | step size | gamma | epoch | ìµœê³  ì„±ëŠ¥(eval) | batch size |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| lr_scheduler | o | StepLR | 3e-5 | 3 | 0.1 | 10 | 0.90709 | 32 |

|   ì‚¬ìš© ì—¬ë¶€ | patience_check| patience_limit|
| --- | --- | --- |
| o | 0 | 3 | 

![image 12](https://github.com/user-attachments/assets/298262d7-edf8-46d4-b6b7-41c9e6c927ff)

